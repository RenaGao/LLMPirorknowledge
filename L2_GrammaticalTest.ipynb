{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer #change model name based on usage \n",
    "\n",
    "# Load LLama model and tokenizer\n",
    "model_name = \"your-llama-model-name\"  # Replace with specific LLama model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Function to query LLama\n",
    "def llama_generate(input_text, max_length=100):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=max_length, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grammatical_properties(dialogues):\n",
    "    results = []\n",
    "    for dialogue in dialogues:\n",
    "        print(f\"Evaluating Dialogue: {dialogue}\")\n",
    "        \n",
    "        properties = {}\n",
    "\n",
    "        # Reference Words\n",
    "        input_text = f\"Resolve the references in this dialogue:\\n{dialogue}\\nProvide the resolved text.\"\n",
    "        properties[\"Reference Words\"] = llama_generate(input_text)\n",
    "\n",
    "        # Noun & Verb Collocations\n",
    "        input_text = f\"Check the noun and verb collocations in this sentence:\\n{dialogue}\\nProvide the list.\"\n",
    "        properties[\"Noun & Verb Collocations\"] = llama_generate(input_text)\n",
    "\n",
    "        # Numbers Agreement\n",
    "        input_text = f\"Analyze the sentence for number agreement:\\n{dialogue}\"\n",
    "        properties[\"Numbers Agreement\"] = llama_generate(input_text)\n",
    "\n",
    "        # Tense Agreement\n",
    "        input_text = f\"Check the verb tense alignment in this dialogue:\\n{dialogue}\"\n",
    "        properties[\"Tense Agreement\"] = llama_generate(input_text)\n",
    "\n",
    "        # Subject-Verb Agreement\n",
    "        input_text = f\"Check subject-verb agreement in this dialogue:\\n{dialogue}\"\n",
    "        properties[\"Subject-Verb Agreement\"] = llama_generate(input_text)\n",
    "\n",
    "        # Speech Acts\n",
    "        input_text = f\"Classify the speech act in this dialogue:\\n{dialogue}\"\n",
    "        properties[\"Speech Acts\"] = llama_generate(input_text)\n",
    "\n",
    "        # Modal Verbs and Expressions\n",
    "        input_text = f\"Analyze modal verbs in this dialogue:\\n{dialogue}\"\n",
    "        properties[\"Modal Verbs\"] = llama_generate(input_text)\n",
    "\n",
    "        # Quantifiers and Numerals\n",
    "        input_text = f\"Check quantifiers and numerals in this dialogue:\\n{dialogue}\"\n",
    "        properties[\"Quantifiers and Numerals\"] = llama_generate(input_text)\n",
    "\n",
    "        # Append results\n",
    "        results.append({\"Dialogue\": dialogue, \"Properties\": properties})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = [\n",
    "    \"John went to the park. He played football there.\",\n",
    "    \"She bought 100 apples.\",\n",
    "    \"Could you open the window?\",\n",
    "] # replace with data in our L2 datasets\n",
    "\n",
    "# Evaluate all dialogues\n",
    "results = evaluate_grammatical_properties(dialogues)\n",
    "\n",
    "# Display results\n",
    "for res in results:\n",
    "    print(f\"Dialogue: {res['Dialogue']}\")\n",
    "    for prop, output in res[\"Properties\"].items():\n",
    "        print(f\"{prop}: {output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
