{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('text', usetex=True)\n",
    "rc('font', family='serif', size=12)  # Adjust size for overall font\n",
    "\n",
    "# Ensure all densities are normalized to sum to 1\n",
    "def normalize_density(density):\n",
    "    return density / np.sum(density)\n",
    "# Mutual Information calculation\n",
    "def kl_divergence(p_density, q_density):\n",
    "    p_density = normalize_density(p_density)\n",
    "    q_density = normalize_density(q_density)\n",
    "    return entropy(p_density, q_density)\n",
    "\n",
    "# Count the number of elements in a list\n",
    "def count_elements(item):\n",
    "    if isinstance(item, list):\n",
    "        return len(item)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DeepSeek V3 for Quantifiers Numerals...\n",
      "Topic: Quantifiers Numerals with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.10156414948041916\n",
      "LLM Mono ENG Gap: 0.05072817216410815\n",
      "LLM Real ENG Gap: 0.008050188427011495\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Thai\n",
      "LLM L2 Thai Gap: 0.05713823787854394\n",
      "LLM Mono ENG Gap: 0.03728506658384205\n",
      "LLM Real ENG Gap: 0.07650307440973682\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.059819339717793664\n",
      "LLM Mono ENG Gap: 0.18053397664293647\n",
      "LLM Real ENG Gap: 0.27511535679976346\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Korean\n",
      "LLM L2 Korean Gap: 0.02061250997899289\n",
      "LLM Mono ENG Gap: 0.07031028602722217\n",
      "LLM Real ENG Gap: 0.09730278397610012\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Malay\n",
      "LLM L2 Malay Gap: 0.07806870065592465\n",
      "LLM Mono ENG Gap: 0.03420051640735154\n",
      "LLM Real ENG Gap: 0.07436729309188021\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.10769326567182824\n",
      "LLM Mono ENG Gap: 0.03700300176051468\n",
      "LLM Real ENG Gap: 0.056795907314168476\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: English\n",
      "LLM L2 English Gap: 0.02410690864252723\n",
      "LLM Mono ENG Gap: 0.02410690864252723\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.07181117632250503\n",
      "LLM Mono ENG Gap: 0.071086347190604\n",
      "LLM Real ENG Gap: 0.07055180327723638\n",
      "**************************************************\n",
      "Processing QWEN 72B for Quantifiers Numerals...\n",
      "Topic: Quantifiers Numerals with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.1374154336692385\n",
      "LLM Mono ENG Gap: 0.02578976582102823\n",
      "LLM Real ENG Gap: 0.008050188427011495\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Thai\n",
      "LLM L2 Thai Gap: 0.061182282011203445\n",
      "LLM Mono ENG Gap: 0.09760229174230953\n",
      "LLM Real ENG Gap: 0.07650307440973682\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.09431657440556947\n",
      "LLM Mono ENG Gap: 0.2862983801024364\n",
      "LLM Real ENG Gap: 0.27511535679976346\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Korean\n",
      "LLM L2 Korean Gap: 0.017450093780878032\n",
      "LLM Mono ENG Gap: 0.11734245054065506\n",
      "LLM Real ENG Gap: 0.09730278397610012\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Malay\n",
      "LLM L2 Malay Gap: 0.060096256194476935\n",
      "LLM Mono ENG Gap: 0.10336586030620945\n",
      "LLM Real ENG Gap: 0.07436729309188021\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.022170120077727153\n",
      "LLM Mono ENG Gap: 0.06427485843696686\n",
      "LLM Real ENG Gap: 0.056795907314168476\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: English\n",
      "LLM L2 English Gap: 0.01765165389115137\n",
      "LLM Mono ENG Gap: 0.01765165389115137\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.14048488290091843\n",
      "LLM Mono ENG Gap: 0.07485137936077593\n",
      "LLM Real ENG Gap: 0.07055180327723638\n",
      "**************************************************\n",
      "Processing LLAMA 70B for Quantifiers Numerals...\n",
      "Topic: Quantifiers Numerals with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.3757393233133418\n",
      "LLM Mono ENG Gap: 0.04570824868925537\n",
      "LLM Real ENG Gap: 0.008050188427011495\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Thai\n",
      "LLM L2 Thai Gap: 0.09289524094288251\n",
      "LLM Mono ENG Gap: 0.025481769627620214\n",
      "LLM Real ENG Gap: 0.07650307440973682\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.059724681261031774\n",
      "LLM Mono ENG Gap: 0.15644882399378388\n",
      "LLM Real ENG Gap: 0.27511535679976346\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Korean\n",
      "LLM L2 Korean Gap: 0.2615999476841643\n",
      "LLM Mono ENG Gap: 0.030649551816211415\n",
      "LLM Real ENG Gap: 0.09730278397610012\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Malay\n",
      "LLM L2 Malay Gap: 0.17409980558531343\n",
      "LLM Mono ENG Gap: 0.01730838053211395\n",
      "LLM Real ENG Gap: 0.07436729309188021\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.10273329572610368\n",
      "LLM Mono ENG Gap: 0.008497457757731232\n",
      "LLM Real ENG Gap: 0.056795907314168476\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: English\n",
      "LLM L2 English Gap: 0.0258134095641128\n",
      "LLM Mono ENG Gap: 0.0258134095641128\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.31319716892886806\n",
      "LLM Mono ENG Gap: 0.024581850963168915\n",
      "LLM Real ENG Gap: 0.07055180327723638\n",
      "**************************************************\n",
      "Processing LLAMA 8B for Quantifiers Numerals...\n",
      "../annotations/LLAMA 8B_output/LLAMA 8B_generation_quantifiers_numerals\\english_dialog\\Problem-Solving_0.json\n",
      "Error reading ../annotations/LLAMA 8B_output/LLAMA 8B_generation_quantifiers_numerals\\english_dialog\\Problem-Solving_0.json: DataFrame constructor not properly called!\n",
      "Topic: Quantifiers Numerals with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.29368675972669195\n",
      "LLM Mono ENG Gap: 0.08630066140326859\n",
      "LLM Real ENG Gap: 0.008050188427011495\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Thai\n",
      "LLM L2 Thai Gap: 0.06366658688313723\n",
      "LLM Mono ENG Gap: 0.01875141124796396\n",
      "LLM Real ENG Gap: 0.07650307440973682\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.02496821666255263\n",
      "LLM Mono ENG Gap: 0.11323772956953829\n",
      "LLM Real ENG Gap: 0.27511535679976346\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Korean\n",
      "LLM L2 Korean Gap: 0.08467333280271033\n",
      "LLM Mono ENG Gap: 0.0037601249895854033\n",
      "LLM Real ENG Gap: 0.09730278397610012\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Malay\n",
      "LLM L2 Malay Gap: 0.1491215671665421\n",
      "LLM Mono ENG Gap: 0.015381394501313178\n",
      "LLM Real ENG Gap: 0.07436729309188021\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.08484164696223898\n",
      "LLM Mono ENG Gap: 0.010482950843099019\n",
      "LLM Real ENG Gap: 0.056795907314168476\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: English\n",
      "LLM L2 English Gap: 0.05925102700019305\n",
      "LLM Mono ENG Gap: 0.05925102700019305\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.053599450674252334\n",
      "LLM Mono ENG Gap: 0.003769946655492915\n",
      "LLM Real ENG Gap: 0.07055180327723638\n",
      "**************************************************\n",
      "Processing GPT 4o 2025 for Quantifiers Numerals...\n",
      "Topic: Quantifiers Numerals with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.36694558154863555\n",
      "LLM Mono ENG Gap: 0.1355156580988118\n",
      "LLM Real ENG Gap: 0.008050188427011495\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Thai\n",
      "LLM L2 Thai Gap: 0.1815743238260093\n",
      "LLM Mono ENG Gap: 0.023542875042181277\n",
      "LLM Real ENG Gap: 0.07650307440973682\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.10421056544583979\n",
      "LLM Mono ENG Gap: 0.08965847723641415\n",
      "LLM Real ENG Gap: 0.27511535679976346\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Korean\n",
      "LLM L2 Korean Gap: 0.09365754477817131\n",
      "LLM Mono ENG Gap: 0.017329803332905364\n",
      "LLM Real ENG Gap: 0.09730278397610012\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Malay\n",
      "LLM L2 Malay Gap: 0.1128651848596681\n",
      "LLM Mono ENG Gap: 0.02230837379910544\n",
      "LLM Real ENG Gap: 0.07436729309188021\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.0701349452809005\n",
      "LLM Mono ENG Gap: 0.028456564915489542\n",
      "LLM Real ENG Gap: 0.056795907314168476\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: English\n",
      "LLM L2 English Gap: 0.09235023881825716\n",
      "LLM Mono ENG Gap: 0.09235023881825716\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.2507241393362221\n",
      "LLM Mono ENG Gap: 0.05197035228853104\n",
      "LLM Real ENG Gap: 0.07055180327723638\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "GENERATION_MODEL_LIST = [\"DeepSeek V3\", \"QWEN 72B\", \"LLAMA 70B\", \"LLAMA 8B\", \"GPT 4o 2025\"]\n",
    "DATASET_NAME = \"ICNALE\"\n",
    "TOPIC = \"Quantifiers Numerals\"\n",
    "ENG_LANGUAGE = 'English'\n",
    "language_mapping = {\n",
    "    'cantonese': 'Cantonese',\n",
    "    'thai': 'Thai',\n",
    "    'japanese': 'Japanese',\n",
    "    'korean': 'Korean',\n",
    "    'malay': 'Malay',\n",
    "    'mandarin': 'Mandarin',\n",
    "    'english': 'English',\n",
    "    'urdu': 'Urdu',\n",
    "}\n",
    "\n",
    "real_language_mapping = {\n",
    "    'HKG': 'Cantonese', \n",
    "    'THA': 'Thai', \n",
    "    'JPN': 'Japanese', \n",
    "    'KOR': 'Korean',\n",
    "    'MYS': 'Malay',\n",
    "    'CHN': 'Mandarin',\n",
    "    'ENS': 'English',\n",
    "    'PAK': 'Urdu'\n",
    "}\n",
    "\n",
    "revert_lan_mapping = {v: k for k, v in language_mapping.items()}\n",
    "revert_lan_real_mapping = {v: k for k, v in real_language_mapping.items()}\n",
    "\n",
    "total_language_list = list(real_language_mapping.values())\n",
    "real_language_list = list(real_language_mapping.keys())\n",
    "\n",
    "res_table = pd.DataFrame(\n",
    "    index=total_language_list,\n",
    "    columns=pd.MultiIndex.from_product([GENERATION_MODEL_LIST, ['L2_generated_gap', 'Mono_eng_gap']])\n",
    ")\n",
    "\n",
    "for MODEL_NAME in GENERATION_MODEL_LIST:\n",
    "    print(f\"Processing {MODEL_NAME} for {TOPIC}...\")\n",
    "\n",
    "\n",
    "    real_path_mapping = {f'{DATASET_NAME}_generation_quantifiers_numerals': \"Quantifiers Numerals\",\n",
    "                    f'{DATASET_NAME}_generation_tense_agreement': \"Tense Agreement\",\n",
    "                    f'{DATASET_NAME}_generation_reference_word': \"Reference Word\",\n",
    "                    f'{DATASET_NAME}_generation_numbers_agreement': \"Numbers Agreement\",\n",
    "                    f'{DATASET_NAME}_generation_speech_acts': \"Speech Acts\",\n",
    "                    f'{DATASET_NAME}_generation_subject_verb_agreement': \"Subject Verb Agreement\",\n",
    "                    f'{DATASET_NAME}_generation_modal_verbs_expressions': \"Modal Verbs Expressions\",\n",
    "                    f'{DATASET_NAME}_generation_noun_verb_collocation': \"Noun Verb Collocation\"\n",
    "                    }\n",
    "\n",
    "    path_mapping = {f'{MODEL_NAME}_generation_quantifiers_numerals': \"Quantifiers Numerals\",\n",
    "                    f'{MODEL_NAME}_generation_tense_agreement': \"Tense Agreement\",\n",
    "                    f'{MODEL_NAME}_generation_reference_word': \"Reference Word\",\n",
    "                    f'{MODEL_NAME}_generation_numbers_agreement': \"Numbers Agreement\",\n",
    "                    f'{MODEL_NAME}_generation_speech_acts': \"Speech Acts\",\n",
    "                    f'{MODEL_NAME}_generation_subject_verb_agreement': \"Subject Verb Agreement\",\n",
    "                    f'{MODEL_NAME}_generation_modal_verbs_expressions': \"Modal Verbs Expressions\",\n",
    "                    f'{MODEL_NAME}_generation_noun_verb_collocation': \"Noun Verb Collocation\"\n",
    "                    }\n",
    "\n",
    "    revert_mapping = {v: k for k, v in path_mapping.items()}\n",
    "    revert_real_mapping = {v: k for k, v in real_path_mapping.items()}\n",
    " \n",
    "    # Put data under /annotations/{MODEL_NAME}_output\n",
    "    path = f'../annotations/{MODEL_NAME}_output'\n",
    "    for root, folders, files in os.walk(path):\n",
    "        folder_list = folders\n",
    "        break\n",
    "\n",
    "    real_path = '../annotations/ICNALE_output'\n",
    "    for root, folders, files in os.walk(real_path):\n",
    "        real_folder_list = folders\n",
    "        break\n",
    "\n",
    "    if not os.path.exists(f\"../result/{MODEL_NAME}_output\"):\n",
    "        os.makedirs(f\"../result/{MODEL_NAME}_output\")\n",
    "        \n",
    "\n",
    "    feature = revert_mapping[TOPIC]\n",
    "    pattern = r\"[\\\\/](?P<language>[^\\\\/]+)_dialog$\"\n",
    "    path = f'../annotations/{MODEL_NAME}_output/{feature}'\n",
    "    all_data = pd.DataFrame()\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(path):\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue \n",
    "        #print(root)\n",
    "        language = re.search(pattern, root).group(1)\n",
    "        #print(language)\n",
    "        for json_file in files:\n",
    "            if json_file.endswith('.json'):\n",
    "                file_path = os.path.join(root, json_file)\n",
    "                try:\n",
    "                    data = pd.read_json(file_path)\n",
    "                    filename = os.path.splitext(json_file)[0]\n",
    "                    data['source_file'] = filename\n",
    "                    data['language'] = language\n",
    "                    all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "                except Exception as e:\n",
    "                    print(file_path)\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "        count += 1\n",
    "\n",
    "    all_data['type'] = TOPIC\n",
    "    all_data['token_num'] = all_data['annotation_tokens'].apply(count_elements)\n",
    "\n",
    "    real_all_data = pd.DataFrame()\n",
    "    def parse_filename(filename):\n",
    "        pattern = r\"SD_(\\w+)_\\d+_.*_(\\d+)_([\\w+]+)\"\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            language = match.group(1) \n",
    "            number = match.group(2)    \n",
    "            chapter = match.group(3)   \n",
    "            return language, number, chapter\n",
    "        return None, None, None\n",
    "\n",
    "    real_feature = revert_real_mapping[TOPIC]\n",
    "    real_path =  f'../annotations/ICNALE_output/{real_feature}'\n",
    "    for root, _, files in os.walk(real_path):\n",
    "        for json_file in files:\n",
    "            if json_file.endswith('.json'):\n",
    "                file_path = os.path.join(root, json_file)\n",
    "                try:\n",
    "                    try:\n",
    "                        data = pd.read_json(file_path, lines=True)\n",
    "                    except Exception as e:\n",
    "                        data = pd.read_json(file_path, lines=False)\n",
    "                    filename = os.path.splitext(json_file)[0]\n",
    "                    language, number, chapter = parse_filename(filename)\n",
    "                    data['source_file'] = filename\n",
    "                    data['language'] = language\n",
    "                    data['number'] = number\n",
    "                    data['chapter'] = chapter\n",
    "                    real_all_data = pd.concat([real_all_data, data], ignore_index=True)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    real_all_data['type'] = TOPIC\n",
    "    real_all_data['token_num'] = real_all_data['annotation_tokens'].apply(count_elements)\n",
    "        \n",
    "    real_counts = real_all_data.groupby(['language', 'source_file'])['token_num'].sum().reset_index()\n",
    "    counts = all_data.groupby(['language', 'source_file'])['token_num'].sum().reset_index()\n",
    "\n",
    "    for target_language in total_language_list:\n",
    "        lang_counts = counts[counts['language'] == revert_lan_mapping[target_language]]['token_num']\n",
    "        eng_lang_counts = counts[counts['language'] == revert_lan_mapping[ENG_LANGUAGE]]['token_num']\n",
    "        real_lang_counts = real_counts[real_counts['language'] == revert_lan_real_mapping[target_language]]['token_num']\n",
    "        real_lang_ens_counts = real_counts[real_counts['language'] == revert_lan_real_mapping[ENG_LANGUAGE]]['token_num']\n",
    "\n",
    "        generated_l2_density = gaussian_kde(lang_counts)\n",
    "        real_l2_density = gaussian_kde(real_lang_counts)\n",
    "        mono_eng_density = gaussian_kde(eng_lang_counts)\n",
    "        real_eng_density = gaussian_kde(real_lang_ens_counts)\n",
    "        x_vals = np.linspace(min(real_lang_counts), min(max(real_lang_counts), 15), 1000)\n",
    "\n",
    "        l2_generated_gap = kl_divergence(generated_l2_density(x_vals), real_l2_density(x_vals))\n",
    "        mono_eng_generated_gap = kl_divergence(mono_eng_density(x_vals), real_l2_density(x_vals))\n",
    "        real_eng_gap = kl_divergence(real_eng_density(x_vals), real_l2_density(x_vals))\n",
    "        \n",
    "        print(f\"Topic: {TOPIC} with L2: {target_language}\")\n",
    "        print(f\"LLM L2 {target_language} Gap: {l2_generated_gap}\")\n",
    "        print(f\"LLM Mono ENG Gap: {mono_eng_generated_gap}\")\n",
    "        print(f\"LLM Real ENG Gap: {real_eng_gap}\")\n",
    "        print(\"*\" * 50)\n",
    "        \n",
    "        res_table.loc[target_language, (MODEL_NAME, 'L2_generated_gap')] = l2_generated_gap\n",
    "        res_table.loc[target_language, (MODEL_NAME, 'Mono_eng_gap')] = mono_eng_generated_gap\n",
    "        \n",
    "        languages = [revert_lan_mapping[target_language], revert_lan_mapping[ENG_LANGUAGE]]\n",
    "        real_languages = [revert_lan_real_mapping[target_language]]\n",
    "\n",
    "\n",
    "if not os.path.exists(f\"../result/{TOPIC}_output\"):\n",
    "    os.makedirs(f\"../result/{TOPIC}_output\")\n",
    "\n",
    "res_table.to_csv(f'../result/{TOPIC}_output/distance_results.csv')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
