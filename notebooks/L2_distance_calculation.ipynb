{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('text', usetex=True)\n",
    "rc('font', family='serif', size=12)  # Adjust size for overall font\n",
    "\n",
    "# Ensure all densities are normalized to sum to 1\n",
    "def normalize_density(density):\n",
    "    return density / np.sum(density)\n",
    "# Mutual Information calculation\n",
    "def kl_divergence(p_density, q_density):\n",
    "    p_density = normalize_density(p_density)\n",
    "    q_density = normalize_density(q_density)\n",
    "    return entropy(p_density, q_density)\n",
    "\n",
    "# Count the number of elements in a list\n",
    "def count_elements(item):\n",
    "    if isinstance(item, list):\n",
    "        return len(item)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_MODEL_LIST = {\n",
    "    \"DeepSeek V3\": {\"model\": \"deepseek/deepseek-chat\", \n",
    "                    \"api_key\": os.getenv(\"DEEPSEEK_API_KEY\")},\n",
    "    \"QWEN 72B\":{\"model\": \"qwen/qwen-2.5-72b-instruct\", \n",
    "                \"api_key\": os.getenv(\"QWEN_API_KEY\")},\n",
    "    \"LLAMA 70B\": {\"model\": \"meta-llama/llama-3.3-70b-instruct\",\n",
    "                 \"api_key\": os.getenv(\"LLAMA_API_KEY\")},\n",
    "    \"Claude 3.5 Haiku\": {\"model\": \"anthropic/claude-3.5-haiku\", \n",
    "                        \"api_key\": os.getenv(\"CLAUDE_API_KEY\")},\n",
    "    \"GPT 4o 2025\": {\"model\": \"gpt-4o\",\n",
    "                    \"api_key\": os.getenv(\"OPENAI_API_KEY\")},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"GPT 4o 2025\"\n",
    "DATASET_NAME = \"ICNALE\"\n",
    "\n",
    "language_mapping = {\n",
    "    'cantonese': 'Cantonese',\n",
    "    'thai': 'Thai',\n",
    "    'japanese': 'Japanese',\n",
    "    'korean': 'Korean',\n",
    "    'malay': 'Malay',\n",
    "    'mandarin': 'Mandarin',\n",
    "    'english': 'English',\n",
    "    'urdu': 'Urdu',\n",
    "}\n",
    "\n",
    "real_language_mapping = {\n",
    "    'HKG': 'Cantonese', \n",
    "    'THA': 'Thai', \n",
    "    'JPN': 'Japanese', \n",
    "    'KOR': 'Korean',\n",
    "    'MYS': 'Malay',\n",
    "    'CHN': 'Mandarin',\n",
    "    'ENS': 'English',\n",
    "    'PAK': 'Urdu'\n",
    "}\n",
    "\n",
    "real_path_mapping = {f'{DATASET_NAME}_generation_quantifiers_numerals': \"Quantifiers Numerals\",\n",
    "                f'{DATASET_NAME}_generation_tense_agreement': \"Tense Agreement\",\n",
    "                f'{DATASET_NAME}_generation_reference_word': \"Reference Word\",\n",
    "                f'{DATASET_NAME}_generation_numbers_agreement': \"Numbers Agreement\",\n",
    "                f'{DATASET_NAME}_generation_speech_acts': \"Speech Acts\",\n",
    "                f'{DATASET_NAME}_generation_subject_verb_agreement': \"Subject Verb Agreement\",\n",
    "                f'{DATASET_NAME}_generation_modal_verbs_expressions': \"Modal Verbs Expressions\",\n",
    "                f'{DATASET_NAME}_generation_noun_verb_collocation': \"Noun Verb Collocation\"\n",
    "                }\n",
    "\n",
    "path_mapping = {f'{MODEL_NAME}_generation_quantifiers_numerals': \"Quantifiers Numerals\",\n",
    "                f'{MODEL_NAME}_generation_tense_agreement': \"Tense Agreement\",\n",
    "                f'{MODEL_NAME}_generation_reference_word': \"Reference Word\",\n",
    "                f'{MODEL_NAME}_generation_numbers_agreement': \"Numbers Agreement\",\n",
    "                f'{MODEL_NAME}_generation_speech_acts': \"Speech Acts\",\n",
    "                f'{MODEL_NAME}_generation_subject_verb_agreement': \"Subject Verb Agreement\",\n",
    "                f'{MODEL_NAME}_generation_modal_verbs_expressions': \"Modal Verbs Expressions\",\n",
    "                f'{MODEL_NAME}_generation_noun_verb_collocation': \"Noun Verb Collocation\"\n",
    "                }\n",
    "\n",
    "revert_mapping = {v: k for k, v in path_mapping.items()}\n",
    "revert_real_mapping = {v: k for k, v in real_path_mapping.items()}\n",
    "\n",
    "revert_lan_mapping = {v: k for k, v in language_mapping.items()}\n",
    "revert_lan_real_mapping = {v: k for k, v in real_language_mapping.items()}\n",
    "\n",
    "total_language_list = list(real_language_mapping.values())\n",
    "real_language_list = list(real_language_mapping.keys())\n",
    "total_feature_list = list(path_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data under /annotations/{MODEL_NAME}_output\n",
    "path = f'../annotations/{MODEL_NAME}_output'\n",
    "for root, folders, files in os.walk(path):\n",
    "    folder_list = folders\n",
    "    break\n",
    "\n",
    "# Put real data under /annotations/ICNALE_annotations\n",
    "real_path = '../annotations/ICNALE_output'\n",
    "for root, folders, files in os.walk(real_path):\n",
    "    real_folder_list = folders\n",
    "    break\n",
    "\n",
    "if not os.path.exists(f\"../result/{MODEL_NAME}_output\"):\n",
    "    os.makedirs(f\"../result/{MODEL_NAME}_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_quantifiers_numerals\n",
      "Topic: Quantifiers Numerals with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.36694558154863555\n",
      "LLM Mono ENG Gap: 0.1355156580988118\n",
      "LLM Real ENG Gap: 0.008050188427011495\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Thai\n",
      "LLM L2 Thai Gap: 0.1815743238260093\n",
      "LLM Mono ENG Gap: 0.023542875042181277\n",
      "LLM Real ENG Gap: 0.07650307440973682\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.10421056544583979\n",
      "LLM Mono ENG Gap: 0.08965847723641415\n",
      "LLM Real ENG Gap: 0.27511535679976346\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Korean\n",
      "LLM L2 Korean Gap: 0.09365754477817131\n",
      "LLM Mono ENG Gap: 0.017329803332905364\n",
      "LLM Real ENG Gap: 0.09730278397610012\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Malay\n",
      "LLM L2 Malay Gap: 0.1128651848596681\n",
      "LLM Mono ENG Gap: 0.02230837379910544\n",
      "LLM Real ENG Gap: 0.07436729309188021\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.0701349452809005\n",
      "LLM Mono ENG Gap: 0.028456564915489542\n",
      "LLM Real ENG Gap: 0.056795907314168476\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: English\n",
      "LLM L2 English Gap: 0.09235023881825716\n",
      "LLM Mono ENG Gap: 0.09235023881825716\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Quantifiers Numerals with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.2507241393362221\n",
      "LLM Mono ENG Gap: 0.05197035228853104\n",
      "LLM Real ENG Gap: 0.07055180327723638\n",
      "**************************************************\n",
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_tense_agreement\n",
      "Topic: Tense Agreement with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.020530454154925944\n",
      "LLM Mono ENG Gap: 0.03396492929292553\n",
      "LLM Real ENG Gap: 0.04933731879460633\n",
      "**************************************************\n",
      "Topic: Tense Agreement with L2: Thai\n",
      "LLM L2 Thai Gap: 0.0719299255595243\n",
      "LLM Mono ENG Gap: 0.25706578606623176\n",
      "LLM Real ENG Gap: 0.2912783260683169\n",
      "**************************************************\n",
      "Topic: Tense Agreement with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.030926893719057293\n",
      "LLM Mono ENG Gap: 0.3050515845109324\n",
      "LLM Real ENG Gap: 0.4247960870293249\n",
      "**************************************************\n",
      "Topic: Tense Agreement with L2: Korean\n",
      "LLM L2 Korean Gap: 0.018731711322702932\n",
      "LLM Mono ENG Gap: 0.034874805534543266\n",
      "LLM Real ENG Gap: 0.040805014009941784\n",
      "**************************************************\n",
      "Topic: Tense Agreement with L2: Malay\n",
      "LLM L2 Malay Gap: 0.15646954926614917\n",
      "LLM Mono ENG Gap: 0.16659736412126394\n",
      "LLM Real ENG Gap: 0.21592523067635705\n",
      "**************************************************\n",
      "Topic: Tense Agreement with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.027691450562017595\n",
      "LLM Mono ENG Gap: 0.2079904078707388\n",
      "LLM Real ENG Gap: 0.2516914412169126\n",
      "**************************************************\n",
      "Topic: Tense Agreement with L2: English\n",
      "LLM L2 English Gap: 0.011975146737679479\n",
      "LLM Mono ENG Gap: 0.011975146737679479\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Tense Agreement with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.13253445019228205\n",
      "LLM Mono ENG Gap: 0.07796777989059478\n",
      "LLM Real ENG Gap: 0.10210153687650725\n",
      "**************************************************\n",
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_reference_word\n",
      "Topic: Reference Word with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.1378468426688875\n",
      "LLM Mono ENG Gap: 0.448604624779678\n",
      "LLM Real ENG Gap: 0.0007124974845258911\n",
      "**************************************************\n",
      "Topic: Reference Word with L2: Thai\n",
      "LLM L2 Thai Gap: 0.5035640948850836\n",
      "LLM Mono ENG Gap: 0.6248497614316217\n",
      "LLM Real ENG Gap: 0.0025656966565811394\n",
      "**************************************************\n",
      "Topic: Reference Word with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.1829481007122792\n",
      "LLM Mono ENG Gap: 0.6947077497739929\n",
      "LLM Real ENG Gap: 0.02910258681453224\n",
      "**************************************************\n",
      "Topic: Reference Word with L2: Korean\n",
      "LLM L2 Korean Gap: 0.3212142207855039\n",
      "LLM Mono ENG Gap: 0.5424487066824948\n",
      "LLM Real ENG Gap: 0.0034573843474590693\n",
      "**************************************************\n",
      "Topic: Reference Word with L2: Malay\n",
      "LLM L2 Malay Gap: 0.1636034633281406\n",
      "LLM Mono ENG Gap: 0.4384908199005576\n",
      "LLM Real ENG Gap: 7.718311368699827e-05\n",
      "**************************************************\n",
      "Topic: Reference Word with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.26080050355537376\n",
      "LLM Mono ENG Gap: 0.5301683531584288\n",
      "LLM Real ENG Gap: 0.001439826093572922\n",
      "**************************************************\n",
      "Topic: Reference Word with L2: English\n",
      "LLM L2 English Gap: 0.44298796154241327\n",
      "LLM Mono ENG Gap: 0.44298796154241327\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Reference Word with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.20545106673182867\n",
      "LLM Mono ENG Gap: 0.5289922987189397\n",
      "LLM Real ENG Gap: 0.0026719112140112036\n",
      "**************************************************\n",
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_numbers_agreement\n",
      "Topic: Numbers Agreement with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.08586800846369774\n",
      "LLM Mono ENG Gap: 0.23096367363582182\n",
      "LLM Real ENG Gap: 0.04765330724379624\n",
      "**************************************************\n",
      "Topic: Numbers Agreement with L2: Thai\n",
      "LLM L2 Thai Gap: 0.09562016564787021\n",
      "LLM Mono ENG Gap: 0.03784495714669208\n",
      "LLM Real ENG Gap: 0.1556913601487725\n",
      "**************************************************\n",
      "Topic: Numbers Agreement with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.010477525112252736\n",
      "LLM Mono ENG Gap: 0.037193445667437874\n",
      "LLM Real ENG Gap: 0.09519210116047698\n",
      "**************************************************\n",
      "Topic: Numbers Agreement with L2: Korean\n",
      "LLM L2 Korean Gap: 0.04302010973183262\n",
      "LLM Mono ENG Gap: 0.10288970577770004\n",
      "LLM Real ENG Gap: 0.11233088663580765\n",
      "**************************************************\n",
      "Topic: Numbers Agreement with L2: Malay\n",
      "LLM L2 Malay Gap: 0.06922295085078026\n",
      "LLM Mono ENG Gap: 0.10909818037527011\n",
      "LLM Real ENG Gap: 0.027533863514064817\n",
      "**************************************************\n",
      "Topic: Numbers Agreement with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.030311823804310144\n",
      "LLM Mono ENG Gap: 0.09893900406438148\n",
      "LLM Real ENG Gap: 0.04265598736040376\n",
      "**************************************************\n",
      "Topic: Numbers Agreement with L2: English\n",
      "LLM L2 English Gap: 0.1296677258530603\n",
      "LLM Mono ENG Gap: 0.1296677258530603\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Numbers Agreement with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.04142398868667954\n",
      "LLM Mono ENG Gap: 0.1018865451768817\n",
      "LLM Real ENG Gap: 0.03498052317729232\n",
      "**************************************************\n",
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_speech_acts\n",
      "Topic: Speech Acts with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.3730254813562591\n",
      "LLM Mono ENG Gap: 0.8173845172189179\n",
      "LLM Real ENG Gap: 0.01469460730337413\n",
      "**************************************************\n",
      "Topic: Speech Acts with L2: Thai\n",
      "LLM L2 Thai Gap: 0.5612065029132831\n",
      "LLM Mono ENG Gap: 1.0991807902014559\n",
      "LLM Real ENG Gap: 0.026499430493513304\n",
      "**************************************************\n",
      "Topic: Speech Acts with L2: Japanese\n",
      "LLM L2 Japanese Gap: 1.1540746954190846\n",
      "LLM Mono ENG Gap: 1.894199913015358\n",
      "LLM Real ENG Gap: 0.16556249895966066\n",
      "**************************************************\n",
      "Topic: Speech Acts with L2: Korean\n",
      "LLM L2 Korean Gap: 1.2412048429077165\n",
      "LLM Mono ENG Gap: 2.267809189063566\n",
      "LLM Real ENG Gap: 0.06132729139664026\n",
      "**************************************************\n",
      "Topic: Speech Acts with L2: Malay\n",
      "LLM L2 Malay Gap: 0.7708878397562531\n",
      "LLM Mono ENG Gap: 1.1844030407314852\n",
      "LLM Real ENG Gap: 0.016788665238141362\n",
      "**************************************************\n",
      "Topic: Speech Acts with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.6176464403804355\n",
      "LLM Mono ENG Gap: 1.1746153358881883\n",
      "LLM Real ENG Gap: 0.015718341702706244\n",
      "**************************************************\n",
      "Topic: Speech Acts with L2: English\n",
      "LLM L2 English Gap: 0.8529099094732795\n",
      "LLM Mono ENG Gap: 0.8529099094732795\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Speech Acts with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.3110224478410538\n",
      "LLM Mono ENG Gap: 0.8216802422427476\n",
      "LLM Real ENG Gap: 0.011977163113212438\n",
      "**************************************************\n",
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_subject_verb_agreement\n",
      "Topic: Subject Verb Agreement with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.04549215703486405\n",
      "LLM Mono ENG Gap: 0.3258914335029988\n",
      "LLM Real ENG Gap: 0.0002875687014294928\n",
      "**************************************************\n",
      "Topic: Subject Verb Agreement with L2: Thai\n",
      "LLM L2 Thai Gap: 0.3106415376585795\n",
      "LLM Mono ENG Gap: 0.5893259860381099\n",
      "LLM Real ENG Gap: 0.013142605216671953\n",
      "**************************************************\n",
      "Topic: Subject Verb Agreement with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.1600294855843895\n",
      "LLM Mono ENG Gap: 0.6852238817880698\n",
      "LLM Real ENG Gap: 0.048983299634202435\n",
      "**************************************************\n",
      "Topic: Subject Verb Agreement with L2: Korean\n",
      "LLM L2 Korean Gap: 0.13561493568276942\n",
      "LLM Mono ENG Gap: 0.39421815506531344\n",
      "LLM Real ENG Gap: 0.008893083377523148\n",
      "**************************************************\n",
      "Topic: Subject Verb Agreement with L2: Malay\n",
      "LLM L2 Malay Gap: 0.061753836222128405\n",
      "LLM Mono ENG Gap: 0.368596062080783\n",
      "LLM Real ENG Gap: 0.002102863520481434\n",
      "**************************************************\n",
      "Topic: Subject Verb Agreement with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.13345315963652063\n",
      "LLM Mono ENG Gap: 0.45482393940891136\n",
      "LLM Real ENG Gap: 0.010301957828794821\n",
      "**************************************************\n",
      "Topic: Subject Verb Agreement with L2: English\n",
      "LLM L2 English Gap: 0.4366852012733849\n",
      "LLM Mono ENG Gap: 0.4366852012733849\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Subject Verb Agreement with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.05658888265596132\n",
      "LLM Mono ENG Gap: 0.2906747490961181\n",
      "LLM Real ENG Gap: 0.01976093376167233\n",
      "**************************************************\n",
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_modal_verbs_expressions\n",
      "Topic: Modal Verbs Expressions with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.31323313077096604\n",
      "LLM Mono ENG Gap: 0.1578196978308165\n",
      "LLM Real ENG Gap: 0.017303769397848903\n",
      "**************************************************\n",
      "Topic: Modal Verbs Expressions with L2: Thai\n",
      "LLM L2 Thai Gap: 0.06439537816281424\n",
      "LLM Mono ENG Gap: 0.12689387756835274\n",
      "LLM Real ENG Gap: 0.07285879408164733\n",
      "**************************************************\n",
      "Topic: Modal Verbs Expressions with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.07297581279309015\n",
      "LLM Mono ENG Gap: 0.3210297645971117\n",
      "LLM Real ENG Gap: 0.28290793317877116\n",
      "**************************************************\n",
      "Topic: Modal Verbs Expressions with L2: Korean\n",
      "LLM L2 Korean Gap: 0.04861401148497933\n",
      "LLM Mono ENG Gap: 0.17280836065004213\n",
      "LLM Real ENG Gap: 0.15246726461563717\n",
      "**************************************************\n",
      "Topic: Modal Verbs Expressions with L2: Malay\n",
      "LLM L2 Malay Gap: 0.04156491203335308\n",
      "LLM Mono ENG Gap: 0.08173720060710617\n",
      "LLM Real ENG Gap: 0.011362800926340677\n",
      "**************************************************\n",
      "Topic: Modal Verbs Expressions with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.02266682517933724\n",
      "LLM Mono ENG Gap: 0.10901344221151765\n",
      "LLM Real ENG Gap: 0.017500324894671168\n",
      "**************************************************\n",
      "Topic: Modal Verbs Expressions with L2: English\n",
      "LLM L2 English Gap: 0.11791945111110794\n",
      "LLM Mono ENG Gap: 0.11791945111110794\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Modal Verbs Expressions with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.09066694907786771\n",
      "LLM Mono ENG Gap: 0.11664516924254849\n",
      "LLM Real ENG Gap: 0.019452079568961778\n",
      "**************************************************\n",
      "../annotations/GPT 4o 2025_output/GPT 4o 2025_generation_noun_verb_collocation\n",
      "Topic: Noun Verb Collocation with L2: Cantonese\n",
      "LLM L2 Cantonese Gap: 0.0726487594238589\n",
      "LLM Mono ENG Gap: 0.0010375691398022881\n",
      "LLM Real ENG Gap: 0.02122381408239568\n",
      "**************************************************\n",
      "Topic: Noun Verb Collocation with L2: Thai\n",
      "LLM L2 Thai Gap: 0.049964365779959746\n",
      "LLM Mono ENG Gap: 0.14210239430012778\n",
      "LLM Real ENG Gap: 0.08869154850888755\n",
      "**************************************************\n",
      "Topic: Noun Verb Collocation with L2: Japanese\n",
      "LLM L2 Japanese Gap: 0.014236230383154379\n",
      "LLM Mono ENG Gap: 0.1847187487238502\n",
      "LLM Real ENG Gap: 0.1169606406857294\n",
      "**************************************************\n",
      "Topic: Noun Verb Collocation with L2: Korean\n",
      "LLM L2 Korean Gap: 0.026378450268402673\n",
      "LLM Mono ENG Gap: 0.14424455493430588\n",
      "LLM Real ENG Gap: 0.10247283387053097\n",
      "**************************************************\n",
      "Topic: Noun Verb Collocation with L2: Malay\n",
      "LLM L2 Malay Gap: 0.016132567568042357\n",
      "LLM Mono ENG Gap: 0.03058962714226407\n",
      "LLM Real ENG Gap: 0.011107706888180552\n",
      "**************************************************\n",
      "Topic: Noun Verb Collocation with L2: Mandarin\n",
      "LLM L2 Mandarin Gap: 0.03682016299226194\n",
      "LLM Mono ENG Gap: 0.09081566933608248\n",
      "LLM Real ENG Gap: 0.056354084376012914\n",
      "**************************************************\n",
      "Topic: Noun Verb Collocation with L2: English\n",
      "LLM L2 English Gap: 0.015329583731748878\n",
      "LLM Mono ENG Gap: 0.015329583731748878\n",
      "LLM Real ENG Gap: 0.0\n",
      "**************************************************\n",
      "Topic: Noun Verb Collocation with L2: Urdu\n",
      "LLM L2 Urdu Gap: 0.00974264856536481\n",
      "LLM Mono ENG Gap: 0.034859555039765094\n",
      "LLM Real ENG Gap: 0.02236274838550313\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# put the data under /data/{MODEL_NAME}_output\n",
    "eng_language = 'English'\n",
    "\n",
    "res_table = pd.DataFrame(\n",
    "    index=total_language_list,\n",
    "    columns=pd.MultiIndex.from_product([total_feature_list, \n",
    "                                        ['L2_generated_gap', 'Mono_eng_gap']])\n",
    ")\n",
    "\n",
    "for topic in total_feature_list:\n",
    "    feature = revert_mapping[topic]\n",
    "    pattern = r\"[\\\\/](?P<language>[^\\\\/]+)_dialog$\"\n",
    "    path = f'../annotations/{MODEL_NAME}_output/{feature}'\n",
    "    print(path)\n",
    "    all_data = pd.DataFrame()\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(path):\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue \n",
    "        #print(root)\n",
    "        language = re.search(pattern, root).group(1)\n",
    "        #print(language)\n",
    "        for json_file in files:\n",
    "            if json_file.endswith('.json'):\n",
    "                file_path = os.path.join(root, json_file)\n",
    "                try:\n",
    "                    data = pd.read_json(file_path)\n",
    "                    filename = os.path.splitext(json_file)[0]\n",
    "                    data['source_file'] = filename\n",
    "                    data['language'] = language\n",
    "                    all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "                except Exception as e:\n",
    "                    print(file_path)\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "        count += 1\n",
    "\n",
    "    all_data['type'] = topic\n",
    "    all_data['token_num'] = all_data['annotation_tokens'].apply(count_elements)\n",
    "\n",
    "    real_all_data = pd.DataFrame()\n",
    "    def parse_filename(filename):\n",
    "        pattern = r\"SD_(\\w+)_\\d+_.*_(\\d+)_([\\w+]+)\"\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            language = match.group(1) \n",
    "            number = match.group(2)    \n",
    "            chapter = match.group(3)   \n",
    "            return language, number, chapter\n",
    "        return None, None, None\n",
    "\n",
    "    real_feature = revert_real_mapping[topic]\n",
    "    real_path =  f'../annotations/ICNALE_output/{real_feature}'\n",
    "    for root, _, files in os.walk(real_path):\n",
    "        for json_file in files:\n",
    "            if json_file.endswith('.json'):\n",
    "                file_path = os.path.join(root, json_file)\n",
    "                try:\n",
    "                    try:\n",
    "                        data = pd.read_json(file_path, lines=True)\n",
    "                    except Exception as e:\n",
    "                        data = pd.read_json(file_path, lines=False)\n",
    "                    filename = os.path.splitext(json_file)[0]\n",
    "                    language, number, chapter = parse_filename(filename)\n",
    "                    data['source_file'] = filename\n",
    "                    data['language'] = language\n",
    "                    data['number'] = number\n",
    "                    data['chapter'] = chapter\n",
    "                    real_all_data = pd.concat([real_all_data, data], ignore_index=True)\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    real_all_data['type'] = topic\n",
    "    real_all_data['token_num'] = real_all_data['annotation_tokens'].apply(count_elements)\n",
    "        \n",
    "    real_counts = real_all_data.groupby(['language', 'source_file'])['token_num'].sum().reset_index()\n",
    "    counts = all_data.groupby(['language', 'source_file'])['token_num'].sum().reset_index()\n",
    "\n",
    "    for target_language in total_language_list:\n",
    "        lang_counts = counts[counts['language'] == revert_lan_mapping[target_language]]['token_num']\n",
    "        #print(lang_counts)\n",
    "        eng_lang_counts = counts[counts['language'] == revert_lan_mapping[eng_language]]['token_num']\n",
    "        real_lang_counts = real_counts[real_counts['language'] == revert_lan_real_mapping[target_language]]['token_num']\n",
    "        real_lang_ens_counts = real_counts[real_counts['language'] == revert_lan_real_mapping[eng_language]]['token_num']\n",
    "\n",
    "        generated_l2_density = gaussian_kde(lang_counts)\n",
    "        real_l2_density = gaussian_kde(real_lang_counts)\n",
    "        mono_eng_density = gaussian_kde(eng_lang_counts)\n",
    "        real_eng_density = gaussian_kde(real_lang_ens_counts)\n",
    "        x_vals = np.linspace(min(real_lang_counts), min(max(real_lang_counts), 15), 1000)\n",
    "\n",
    "        l2_generated_gap = kl_divergence(generated_l2_density(x_vals), real_l2_density(x_vals))\n",
    "        mono_eng_generated_gap = kl_divergence(mono_eng_density(x_vals), real_l2_density(x_vals))\n",
    "        real_eng_gap = kl_divergence(real_eng_density(x_vals), real_l2_density(x_vals))\n",
    "        \n",
    "        print(f\"Topic: {topic} with L2: {target_language}\")\n",
    "        print(f\"LLM L2 {target_language} Gap: {l2_generated_gap}\")\n",
    "        print(f\"LLM Mono ENG Gap: {mono_eng_generated_gap}\")\n",
    "        print(f\"LLM Real ENG Gap: {real_eng_gap}\")\n",
    "        print(\"*\" * 50)\n",
    "        \n",
    "        res_table.loc[target_language, (topic, 'L2_generated_gap')] = l2_generated_gap\n",
    "        res_table.loc[target_language, (topic, 'Mono_eng_gap')] = mono_eng_generated_gap\n",
    "        \n",
    "        languages = [revert_lan_mapping[target_language], revert_lan_mapping[eng_language]]\n",
    "        real_languages = [revert_lan_real_mapping[target_language]]\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        for language in languages:\n",
    "            lang_counts = counts[counts['language'] == language]['token_num']\n",
    "            density = gaussian_kde(lang_counts)\n",
    "            x_vals = np.linspace(min(lang_counts), max(lang_counts), 1000)\n",
    "            y_vals = density(x_vals)\n",
    "            label = language_mapping[language] + \"-Generated\"\n",
    "            plt.plot(x_vals, y_vals, label=label)\n",
    "\n",
    "        for language in real_languages:\n",
    "            lang_counts = real_counts[real_counts['language'] == language]['token_num']\n",
    "            density = gaussian_kde(lang_counts)\n",
    "            x_vals = np.linspace(min(lang_counts), max(lang_counts), 1000)\n",
    "            y_vals = density(x_vals)\n",
    "            label = real_language_mapping[language] + \"-Human\"\n",
    "            plt.plot(x_vals, y_vals, label=label)\n",
    "        \n",
    "        plt.title(f'{topic}', fontsize=35)\n",
    "        plt.xlabel('Count', fontsize=35)\n",
    "        plt.ylabel('Density', fontsize=35)\n",
    "        plt.xticks(fontsize=25)\n",
    "        plt.yticks(fontsize=25)\n",
    "        plt.legend(fontsize=20)\n",
    "        if topic == \"Quantifiers Numerals\":\n",
    "            plt.xlim(0, 30)\n",
    "        else:\n",
    "            plt.xlim(max(min(lang_counts) - 1, 0), min(max(lang_counts), 50))\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists(f\"../result/{MODEL_NAME}_output/{target_language}\"):\n",
    "            os.makedirs(f\"../result/{MODEL_NAME}_output/{target_language}\")\n",
    "        plt.savefig(f\"../result/{MODEL_NAME}_output/{target_language}/\" + topic + \"_\" + target_language + \".pdf\")\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "res_table.to_csv(f'../result/{MODEL_NAME}_output/distance_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Quantifiers Numerals\"\n",
    "feature = revert_mapping[topic]\n",
    "pattern = r\"([^/]+)_dialog$\"\n",
    "path = f'../data/gpt_annotations/{feature}'\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "count = 0\n",
    "for root, _, files in os.walk(path):\n",
    "    if count == 0:\n",
    "        count = count+1\n",
    "        continue \n",
    "    language = re.search(pattern, root).group(1)\n",
    "    for json_file in files:\n",
    "        if json_file.endswith('.json'):\n",
    "            file_path = os.path.join(root, json_file)\n",
    "            try:\n",
    "                data = pd.read_json(file_path)\n",
    "                filename = os.path.splitext(json_file)[0]\n",
    "                data['source_file'] = filename\n",
    "                data['language'] = language\n",
    "                all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "    count = count + 1\n",
    "    \n",
    "real_all_data = pd.DataFrame()\n",
    "def parse_filename(filename):\n",
    "    pattern = r\"SD_(\\w+)_\\d+_.*_(\\d+)_([\\w+]+)\"\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        language = match.group(1) \n",
    "        number = match.group(2)    \n",
    "        chapter = match.group(3)   \n",
    "        return language, number, chapter\n",
    "    return None, None, None\n",
    "\n",
    "real_feature = revert_real_mapping[topic]\n",
    "real_path =  f'../data/ICNALE_annotations/{real_feature}'\n",
    "for root, _, files in os.walk(real_path):\n",
    "    for json_file in files:\n",
    "        if json_file.endswith('.json'):\n",
    "            file_path = os.path.join(root, json_file)\n",
    "            try:\n",
    "                data = pd.read_json(file_path)\n",
    "                filename = os.path.splitext(json_file)[0]\n",
    "                language, number, chapter = parse_filename(filename)\n",
    "                data['source_file'] = filename\n",
    "                data['language'] = language\n",
    "                data['number'] = number\n",
    "                data['chapter'] = chapter\n",
    "                real_all_data = pd.concat([real_all_data, data], ignore_index=True)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "if topic == \"Modal Verbs Expressions\":   \n",
    "    real_all_data['type'] = 'modal_verb_annotation'\n",
    "real_all_data =  real_all_data[real_all_data['language'].isin(real_language_list)]\n",
    "    \n",
    "if feature in [revert_mapping['Reference Word'],\n",
    "            revert_mapping['Numbers Agreement'],\n",
    "            revert_mapping['Modal Verbs Expressions'],\n",
    "            revert_mapping['Noun Verb Collocation']\n",
    "]:\n",
    "    all_data['token_num'] = 1\n",
    "else:\n",
    "    all_data['token_num'] = all_data['annotation_token'].apply(count_elements)\n",
    "\n",
    "if real_feature in [revert_real_mapping['Reference Word'],\n",
    "            revert_real_mapping['Numbers Agreement'],\n",
    "            revert_real_mapping['Modal Verbs Expressions'],\n",
    "            revert_real_mapping['Noun Verb Collocation']]:\n",
    "    real_all_data['token_num'] = 1\n",
    "else:\n",
    "    real_all_data['token_num'] = real_all_data['annotation_token'].apply(count_elements)\n",
    "    \n",
    "real_counts = real_all_data.groupby(['language', 'source_file'])['token_num'].sum().reset_index()\n",
    "counts = all_data.groupby(['language', 'source_file'])['token_num'].sum().reset_index()\n",
    "\n",
    "\n",
    "languages = [revert_lan_mapping['THA'], revert_lan_mapping['ENG']]\n",
    "real_languages = [revert_lan_real_mapping['THA'], revert_lan_real_mapping['ENG']]\n",
    "\n",
    "for language in languages:\n",
    "    lang_counts = counts[counts['language'] == language]['token_num']\n",
    "    density = gaussian_kde(lang_counts)\n",
    "    x_vals = np.linspace(min(lang_counts), max(lang_counts), 1000)\n",
    "    y_vals = density(x_vals)\n",
    "    plt.plot(x_vals, y_vals, label=language)\n",
    "    \n",
    "plt.title(f'Density Estimation for {topic} by Language')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title=\"Language\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "for language in real_languages:\n",
    "    lang_counts = real_counts[real_counts['language'] == language]['token_num']\n",
    "    density = gaussian_kde(lang_counts)\n",
    "    x_vals = np.linspace(min(lang_counts), max(lang_counts), 1000)\n",
    "    y_vals = density(x_vals)\n",
    "    plt.plot(x_vals, y_vals, label=language)\n",
    "    \n",
    "plt.title(f'Density Estimation for {topic} by Real Language')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title=\"Language\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
